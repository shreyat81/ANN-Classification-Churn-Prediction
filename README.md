**Customer Churn Prediction Using Artificial Neural Networks**

This project predicts customer churn using an Artificial Neural Network (ANN) trained on the popular Churn_Modelling.csv dataset. The goal is to determine whether a customer is likely to leave a bank, based on features like geography, balance, credit score, etc.

**Project Structure:**
annclassification/
â”œâ”€â”€ Churn_Modelling.csv               # Dataset
â”œâ”€â”€ prediction.ipynb                  # Inference using trained model
â”œâ”€â”€ hyperparametertuningann.ipynb    # Hyperparameter tuning and ANN training
â”œâ”€â”€ experiments.ipynb                # Model evaluation and experiment logs
â”œâ”€â”€ model.h5                          # Trained ANN model
â”œâ”€â”€ scaler.pkl                        # StandardScaler used on features
â”œâ”€â”€ label_encoder_gender.pkl         # Encoder for 'Gender' column
â”œâ”€â”€ onehot_encoder_geo.pkl           # Encoder for 'Geography' column
â”œâ”€â”€ salaryregression.ipynb           # Additional regression experiment (optional)
â”œâ”€â”€ requirements.txt                 # Dependencies
â””â”€â”€ README.md                        # Project Documentation

**ğŸ” Problem Statement**

Churn is the percentage of service subscribers who discontinue their subscriptions within a given time period. Reducing churn is critical for business growth. This project uses deep learning (ANN) to classify whether a customer will churn based on features like:
	â€¢	Credit Score
	â€¢	Age
	â€¢	Balance
	â€¢	Gender
	â€¢	Geography
	â€¢	Tenure
	â€¢	Estimated Salary
	â€¢	Number of Products
	â€¢	Active Membership

â¸»

**ğŸ“Š Dataset**
	â€¢	Source: Churn_Modelling.csv
	â€¢	Samples: 10,000 customer records
	â€¢	Target: Exited column (0 = not churned, 1 = churned)

â¸»

**ğŸ”§ Preprocessing**
	â€¢	Feature Engineering:
	â€¢	Label Encoding for Gender
	â€¢	OneHot Encoding for Geography
	â€¢	Scaling:
	â€¢	Features scaled using StandardScaler
	â€¢	Saved Models:
	â€¢	Encoders and scalers are saved using pickle for reuse during inference.

â¸»

**ğŸ§ª Model Development**
	â€¢	Frameworks Used: TensorFlow + Keras (via scikeras)
	â€¢	Model Architecture:
	â€¢	Input layer based on encoded features
	â€¢	Two hidden layers (with ReLU activation)
	â€¢	Output layer with sigmoid activation
	â€¢	Loss Function: Binary Crossentropy
	â€¢	Optimizer: Adam
	â€¢	Evaluation Metrics: Accuracy, Precision, Recall, F1-score, AUC

â¸»

**ğŸ” Hyperparameter Tuning**

Performed using GridSearchCV with KerasClassifier via scikeras. Tuned parameters:
	â€¢	Number of neurons
	â€¢	Batch size
	â€¢	Epochs
	â€¢	Optimizer choice

Results and best parameters are documented in hyperparametertuningann.ipynb.

â¸»

**ğŸ§ª Experiments & Results**

Model evaluation includes:
	â€¢	Confusion Matrix
	â€¢	ROC Curve
	â€¢	Classification Report
	â€¢	Accuracy trends across different hyperparameter combinations

Refer to experiments.ipynb for detailed analysis.

â¸»

**ğŸš€ Inference**

To predict churn for new customer data:
	1.	Apply the same label/one-hot encoding.
	2.	Scale input using scaler.pkl
	3.	Load model.h5 and make predictions using prediction.ipynb.

â¸»

**ğŸ’» Tech Stack**
	â€¢	Python 3.x
	â€¢	TensorFlow 2.15.0
	â€¢	Scikit-learn
	â€¢	Pandas, NumPy, Matplotlib
	â€¢	Scikeras
	â€¢	Streamlit (optional for web deployment)

**ğŸ§ª Running the Notebooks**

Open and execute:
	â€¢	hyperparametertuningann.ipynb: To tune/train the model
	â€¢	experiments.ipynb: To review model performance
	â€¢	prediction.ipynb: To make predictions on new data

â¸»

ğŸŒ Future Improvements
	â€¢	Add Streamlit-based web UI for interactive prediction
	â€¢	Deploy as Flask/FastAPI backend service
	â€¢	Try ensemble models (XGBoost, LightGBM) for comparison
